{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building Multi-label Classifiers \n",
    "### Base Classifiers to test: Binary Relevance (no correlation), Binary Relevance (with correlation), Multi-label Random Forest, Multi-label Decision Tree, Classifier Chain, Binary Releveance with Stacking Aggregation, Cross-Coupling Aggregation (to combat class-imbalances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generic library imports and data import\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv \n",
    "import ast\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "data = pd.read_csv('../Data_sets/Master_cleaned.csv')\n",
    "\n",
    "#Functions\n",
    "\n",
    "def remove_unwanted_observations(data, unwanted_observations = [\"['Oily', 'Sensitive']\",\n",
    "                                                                \"['Dry', 'Normal', 'Oily']\",\n",
    "                                                                \"['Dry', 'Oily']\",\n",
    "                                                                \"['Dry', 'Normal', 'Oily', 'Sensitive']\",\n",
    "                                                                \"['Combination', 'Dry', 'Oily', 'Sensitive']\",\n",
    "                                                                \"['Normal', 'Oily']\"\n",
    "                                                                ]):\n",
    "    for observation in unwanted_observations:\n",
    "        data = data[data.Skin_Type != observation]\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specific Libary imports and functions\n",
    "from sklearn.preprocessing import MultiLabelBinarizer, LabelEncoder\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.model_selection import KFold, cross_validate, cross_val_predict, cross_val_score, GridSearchCV, train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import SVC\n",
    "import sklearn.metrics as metrics\n",
    "from skmultilearn.problem_transform import LabelPowerset, BinaryRelevance, ClassifierChain\n",
    "from skmultilearn.adapt import MLkNN\n",
    "from skmultilearn.adapt import BRkNNaClassifier\n",
    "from skmultilearn.ensemble import RakelD\n",
    "import time\n",
    "\n",
    "\n",
    "def grid_search (model, search_space):\n",
    "    pipe = Pipeline([(\"classifier\", model)])\n",
    "    gs = GridSearchCV(pipe, search_space, scoring = \"accuracy\", cv= kf)\n",
    "    gs.fit(X_train, y_train)\n",
    "    return gs.best_estimator_.get_params()[\"classifier\"]\n",
    "\n",
    "def get_cross_val_results (clf, base_classifier, X, y, X_test,y_test):\n",
    "    try: \n",
    "        model = clf(classifier = best_classifier)\n",
    "    except TypeError:\n",
    "        model = clf(base_classifier = best_classifier)\n",
    "    results = cross_validate(model, X, y, cv= kf, scoring =('accuracy', \"f1_weighted\"), return_train_score = True)\n",
    "    # train results \n",
    "    train_accuracy = results['train_accuracy'].mean()\n",
    "    train_f1 = results['train_f1_weighted']\n",
    "    print(model)\n",
    "    print(\"Training Accuracy = %.04f +/- %.04f\" % (train_accuracy.mean(), train_accuracy.std()*2))\n",
    "    print(\"Training F1 Score = %.04f +/- %.04f\" % (train_f1.mean(), train_f1.std()*2))\n",
    "\n",
    "    # test results\n",
    "    y_pred = cross_val_predict(model, X_test, y_test, cv=kf)\n",
    "    test_accuracy = results['test_accuracy'].mean()\n",
    "    test_f1 = results['test_f1_weighted']\n",
    "    print(\"Test Accuracy = %.04f +/- %.04f\" % (test_accuracy.mean(), test_accuracy.std()*2))\n",
    "    print(\"Test F1 Score = %.04f +/- %.04f\" % (test_f1.mean(), test_f1.std()*2))\n",
    "    print(\"Hamming Loss = %.04f\" % metrics.hamming_loss(y_test, y_pred))\n",
    "    \n",
    "def rfc_grid_search(model, hyperparameters):\n",
    "    gs = GridSearchCV(model, hyperparameters, scoring = ham_loss, cv= kf)\n",
    "    gs.fit(X_train, y_train)\n",
    "    return gs.best_estimator_.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                        Product               Brand  \\\n",
       "0                     #InstantDetox Facial Mask            Biobelle   \n",
       "1                           #Peachy Facial Mask            Biobelle   \n",
       "2                       #Rise&Shine Facial Mask            Biobelle   \n",
       "3                       #Ros√©AllDay Facial Mask            Biobelle   \n",
       "4                       #VitaminSea Facial Mask            Biobelle   \n",
       "...                                         ...                 ...   \n",
       "2019  Youthful Vitamin C Fresh Radiance Essence                 No7   \n",
       "2020                      Yuza Sorbet Day Cream            Erborian   \n",
       "2021                Yuza Sorbet Night Treatment            Erborian   \n",
       "2022               Yuzu Overnight Moisture Mask  Earth Therapeutics   \n",
       "2023                             pHenomenal Gel                Pixi   \n",
       "\n",
       "                                            Ingredients  Price  \\\n",
       "0     Water, Butylene Glycol, Glycerin, Trehalose, H...   3.99   \n",
       "1     Water, Methylpropanediol, Butylene Glycol, Gly...   3.99   \n",
       "2     Water, Glycerin, Butylene Glycol, Triethylhexa...   3.99   \n",
       "3     Water, Methylpropanediol, Glycerin, Propanedio...   3.99   \n",
       "4     Water, Butylene Glycol, Glycerin, Hydroxyaceto...   3.99   \n",
       "...                                                 ...    ...   \n",
       "2019  Aqua (Water), Butylene Glycol, Glycerin, Gluco...  24.99   \n",
       "2020  Aqua/Water, Cyclomethicone, Glycerin, Nylon-12...  48.00   \n",
       "2021  Aqua/Water, Cyclomethicone, Glycerin, Cetearyl...  55.00   \n",
       "2022  Water (Aqua), Propanediol, Glycerin, Hydrogena...   7.00   \n",
       "2023  Aqua/Water/Eau, Glycerin, Glycereth-26, Betain...  24.00   \n",
       "\n",
       "                                              Skin_Type  Combination  Dry  \\\n",
       "0                                              ['Oily']            0    0   \n",
       "1                                               ['Dry']            0    1   \n",
       "2                                       ['Combination']            1    0   \n",
       "3                                       ['Combination']            1    0   \n",
       "4                                               ['Dry']            0    1   \n",
       "...                                                 ...          ...  ...   \n",
       "2019           ['Combination', 'Dry', 'Normal', 'Oily']            1    1   \n",
       "2020  ['Combination', 'Dry', 'Normal', 'Oily', 'Sens...            1    1   \n",
       "2021  ['Combination', 'Dry', 'Normal', 'Oily', 'Sens...            1    1   \n",
       "2022      ['Combination', 'Dry', 'Normal', 'Sensitive']            1    1   \n",
       "2023                                           ['Oily']            0    0   \n",
       "\n",
       "      Normal  Oily  Sensitive  ... num_of_Emollients num_of_Hydration  \\\n",
       "0          0     1          0  ...                 0                0   \n",
       "1          0     0          0  ...                 0                0   \n",
       "2          0     0          0  ...                 0                0   \n",
       "3          0     0          0  ...                 0                0   \n",
       "4          0     0          0  ...                 0                0   \n",
       "...      ...   ...        ...  ...               ...              ...   \n",
       "2019       1     1          0  ...                 0                0   \n",
       "2020       1     1          1  ...                 1                0   \n",
       "2021       1     1          1  ...                 2                0   \n",
       "2022       1     0          1  ...                 2                0   \n",
       "2023       0     1          0  ...                 0                0   \n",
       "\n",
       "     num_of_Skin-Restoring num_of_Plant Extracts  num_of_Preservatives  \\\n",
       "0                        0                     0                     0   \n",
       "1                        0                     0                     0   \n",
       "2                        0                     0                     0   \n",
       "3                        0                     1                     2   \n",
       "4                        0                     1                     0   \n",
       "...                    ...                   ...                   ...   \n",
       "2019                     0                     2                     3   \n",
       "2020                     0                     1                     1   \n",
       "2021                     0                     0                     0   \n",
       "2022                     0                     1                     0   \n",
       "2023                     0                     0                     0   \n",
       "\n",
       "     num_of_Skin-Softening num_of_Sensitizing  num_of_Skin-Replenishing  \\\n",
       "0                        0                  0                         1   \n",
       "1                        0                  0                         1   \n",
       "2                        0                  0                         1   \n",
       "3                        0                  0                         2   \n",
       "4                        0                  0                         1   \n",
       "...                    ...                ...                       ...   \n",
       "2019                     0                  0                         2   \n",
       "2020                     0                  0                         1   \n",
       "2021                     0                  0                         1   \n",
       "2022                     0                  0                         1   \n",
       "2023                     0                  0                         1   \n",
       "\n",
       "                                                  top_3  \\\n",
       "0          ['Butylene Glycol', 'Glycerin', 'Trehalose']   \n",
       "1     ['Methylpropanediol', 'Butylene Glycol', 'Glyc...   \n",
       "2     ['Glycerin', 'Butylene Glycol', 'Triethylhexan...   \n",
       "3      ['Methylpropanediol', 'Glycerin', 'Propanediol']   \n",
       "4     ['Butylene Glycol', 'Glycerin', 'Hydroxyacetop...   \n",
       "...                                                 ...   \n",
       "2019  ['Butylene Glycol', 'Glycerin', 'Gluconolactone']   \n",
       "2020         ['Cyclomethicone', 'Glycerin', 'Nylon-12']   \n",
       "2021  ['Cyclomethicone', 'Glycerin', 'Cetearyl Alcoh...   \n",
       "2022  ['Propanediol', 'Glycerin', 'Hydrogenated Poly...   \n",
       "2023            ['Glycerin', 'Glycereth-26', 'Betaine']   \n",
       "\n",
       "                                     top3_category_list  \n",
       "0     ['Texture Enhancer', 'Skin-Replenishing, Skin-...  \n",
       "1     [None, 'Texture Enhancer', 'Skin-Replenishing,...  \n",
       "2     ['Skin-Replenishing, Skin-Restoring', 'Texture...  \n",
       "3     [None, 'Skin-Replenishing, Skin-Restoring', None]  \n",
       "4     ['Texture Enhancer', 'Skin-Replenishing, Skin-...  \n",
       "...                                                 ...  \n",
       "2019  ['Texture Enhancer', 'Skin-Replenishing, Skin-...  \n",
       "2020  ['Emollients', 'Skin-Replenishing, Skin-Restor...  \n",
       "2021  ['Emollients', 'Skin-Replenishing, Skin-Restor...  \n",
       "2022  [None, 'Skin-Replenishing, Skin-Restoring', None]  \n",
       "2023  ['Skin-Replenishing, Skin-Restoring', None, None]  \n",
       "\n",
       "[2024 rows x 30 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Product</th>\n      <th>Brand</th>\n      <th>Ingredients</th>\n      <th>Price</th>\n      <th>Skin_Type</th>\n      <th>Combination</th>\n      <th>Dry</th>\n      <th>Normal</th>\n      <th>Oily</th>\n      <th>Sensitive</th>\n      <th>...</th>\n      <th>num_of_Emollients</th>\n      <th>num_of_Hydration</th>\n      <th>num_of_Skin-Restoring</th>\n      <th>num_of_Plant Extracts</th>\n      <th>num_of_Preservatives</th>\n      <th>num_of_Skin-Softening</th>\n      <th>num_of_Sensitizing</th>\n      <th>num_of_Skin-Replenishing</th>\n      <th>top_3</th>\n      <th>top3_category_list</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>#InstantDetox Facial Mask</td>\n      <td>Biobelle</td>\n      <td>Water, Butylene Glycol, Glycerin, Trehalose, H...</td>\n      <td>3.99</td>\n      <td>['Oily']</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>['Butylene Glycol', 'Glycerin', 'Trehalose']</td>\n      <td>['Texture Enhancer', 'Skin-Replenishing, Skin-...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>#Peachy Facial Mask</td>\n      <td>Biobelle</td>\n      <td>Water, Methylpropanediol, Butylene Glycol, Gly...</td>\n      <td>3.99</td>\n      <td>['Dry']</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>['Methylpropanediol', 'Butylene Glycol', 'Glyc...</td>\n      <td>[None, 'Texture Enhancer', 'Skin-Replenishing,...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>#Rise&amp;Shine Facial Mask</td>\n      <td>Biobelle</td>\n      <td>Water, Glycerin, Butylene Glycol, Triethylhexa...</td>\n      <td>3.99</td>\n      <td>['Combination']</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>['Glycerin', 'Butylene Glycol', 'Triethylhexan...</td>\n      <td>['Skin-Replenishing, Skin-Restoring', 'Texture...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>#Ros√©AllDay Facial Mask</td>\n      <td>Biobelle</td>\n      <td>Water, Methylpropanediol, Glycerin, Propanedio...</td>\n      <td>3.99</td>\n      <td>['Combination']</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>['Methylpropanediol', 'Glycerin', 'Propanediol']</td>\n      <td>[None, 'Skin-Replenishing, Skin-Restoring', None]</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>#VitaminSea Facial Mask</td>\n      <td>Biobelle</td>\n      <td>Water, Butylene Glycol, Glycerin, Hydroxyaceto...</td>\n      <td>3.99</td>\n      <td>['Dry']</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>['Butylene Glycol', 'Glycerin', 'Hydroxyacetop...</td>\n      <td>['Texture Enhancer', 'Skin-Replenishing, Skin-...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2019</th>\n      <td>Youthful Vitamin C Fresh Radiance Essence</td>\n      <td>No7</td>\n      <td>Aqua (Water), Butylene Glycol, Glycerin, Gluco...</td>\n      <td>24.99</td>\n      <td>['Combination', 'Dry', 'Normal', 'Oily']</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>3</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>['Butylene Glycol', 'Glycerin', 'Gluconolactone']</td>\n      <td>['Texture Enhancer', 'Skin-Replenishing, Skin-...</td>\n    </tr>\n    <tr>\n      <th>2020</th>\n      <td>Yuza Sorbet Day Cream</td>\n      <td>Erborian</td>\n      <td>Aqua/Water, Cyclomethicone, Glycerin, Nylon-12...</td>\n      <td>48.00</td>\n      <td>['Combination', 'Dry', 'Normal', 'Oily', 'Sens...</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>['Cyclomethicone', 'Glycerin', 'Nylon-12']</td>\n      <td>['Emollients', 'Skin-Replenishing, Skin-Restor...</td>\n    </tr>\n    <tr>\n      <th>2021</th>\n      <td>Yuza Sorbet Night Treatment</td>\n      <td>Erborian</td>\n      <td>Aqua/Water, Cyclomethicone, Glycerin, Cetearyl...</td>\n      <td>55.00</td>\n      <td>['Combination', 'Dry', 'Normal', 'Oily', 'Sens...</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>...</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>['Cyclomethicone', 'Glycerin', 'Cetearyl Alcoh...</td>\n      <td>['Emollients', 'Skin-Replenishing, Skin-Restor...</td>\n    </tr>\n    <tr>\n      <th>2022</th>\n      <td>Yuzu Overnight Moisture Mask</td>\n      <td>Earth Therapeutics</td>\n      <td>Water (Aqua), Propanediol, Glycerin, Hydrogena...</td>\n      <td>7.00</td>\n      <td>['Combination', 'Dry', 'Normal', 'Sensitive']</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>...</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>['Propanediol', 'Glycerin', 'Hydrogenated Poly...</td>\n      <td>[None, 'Skin-Replenishing, Skin-Restoring', None]</td>\n    </tr>\n    <tr>\n      <th>2023</th>\n      <td>pHenomenal Gel</td>\n      <td>Pixi</td>\n      <td>Aqua/Water/Eau, Glycerin, Glycereth-26, Betain...</td>\n      <td>24.00</td>\n      <td>['Oily']</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>['Glycerin', 'Glycereth-26', 'Betaine']</td>\n      <td>['Skin-Replenishing, Skin-Restoring', None, None]</td>\n    </tr>\n  </tbody>\n</table>\n<p>2024 rows √ó 30 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Post Processing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Dataset sizes:\n\tTrain (1407, 11)\n\tTest (603, 11)\n"
     ]
    }
   ],
   "source": [
    "#Split Data\n",
    "\n",
    "X = data[data.columns[17:28]].values\n",
    "y = data.Skin_Type\n",
    "\n",
    "data = remove_unwanted_observations(data)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, shuffle=True, test_size=0.3, random_state = 1024, stratify=y)\n",
    "\n",
    "print(\"Dataset sizes:\\n\\tTrain %s\\n\\tTest %s\" % (X_train.shape,X_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array(['Combination', 'Dry', 'Normal', 'Oily', 'Sensitive'], dtype=object)"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "y_train = y_train.apply(ast.literal_eval)\n",
    "y_test = y_test.apply(ast.literal_eval)\n",
    "\n",
    "mlb=MultiLabelBinarizer()\n",
    "y_train = mlb.fit_transform(y_train)\n",
    "y_test = mlb.transform(y_test)\n",
    "mlb.classes_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.029850746268656716"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "dummy = DummyClassifier(strategy= 'uniform', random_state=1024)\n",
    "dummy.fit(X_train, y_train)\n",
    "dummy.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy =  0.029850746268656716\nF1 Score =  0.5882546298802469\nHamming Loss 0.5058043117744611\n"
     ]
    }
   ],
   "source": [
    "p = dummy.predict(X_test)\n",
    "print(\"Accuracy = \", metrics.accuracy_score(y_test,p))\n",
    "print(\"F1 Score = \", metrics.f1_score(y_test,p, average = \"weighted\"))\n",
    "print(\"Hamming Loss\", metrics.hamming_loss(y_test, p))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Problem Transformation Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=5, shuffle = True, random_state=1024)\n",
    "ham_loss = metrics.make_scorer(metrics.hamming_loss, greater_is_better= False)\n",
    "mlb2 = MultiLabelBinarizer()\n",
    "y = mlb2.fit_transform(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3-1. One vs the Rest Classifier (Binary Relevance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_space1 = [{'classifier':[DecisionTreeClassifier()], 'classifier__max_depth' :[5,6,7,8,9],\n",
    "    'classifier__max_leaf_nodes': [5,6,7,8,9,10,15]},{'classifier': [RandomForestClassifier()], 'classifier__n_estimators': [5,8,10,12,14,15],'classifier__max_features': [[8,9,10,11], \"auto\", 'sqrt', 'log2']}, {'classifier': [SVC()], 'classifier__kernel':['rbf', 'linear']},{'classifier': [MultinomialNB()], 'classifier__alpha': [.7, 1.0]}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "BinaryRelevance(classifier=DecisionTreeClassifier(max_depth=5,\n                                                  max_leaf_nodes=5),\n                require_dense=[True, True])\nTraining Accuracy = 0.4451 +/- 0.0000\nTraining F1 Score = 0.8525 +/- 0.0046\nTest Accuracy = 0.4158 +/- 0.0000\nTest F1 Score = 0.8455 +/- 0.0177\nHamming Loss = 0.2779\n"
     ]
    }
   ],
   "source": [
    "best_classifier = grid_search(BinaryRelevance(), search_space1)\n",
    "get_cross_val_results(BinaryRelevance, best_classifier, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3-2. Classifer Chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "ClassifierChain(classifier=DecisionTreeClassifier(max_depth=5,\n                                                  max_leaf_nodes=5),\n                require_dense=[True, True])\nTraining Accuracy = 0.4586 +/- 0.0000\nTraining F1 Score = 0.8525 +/- 0.0042\nTest Accuracy = 0.4513 +/- 0.0000\nTest F1 Score = 0.8494 +/- 0.0210\nHamming Loss = 0.2713\n"
     ]
    }
   ],
   "source": [
    "best_classifier = grid_search(ClassifierChain(), search_space1)\n",
    "get_cross_val_results(ClassifierChain, best_classifier, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3-3. Label Powerset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "LabelPowerset(classifier=DecisionTreeClassifier(max_depth=5, max_leaf_nodes=5),\n              require_dense=[True, True])\nTraining Accuracy = 0.4595 +/- 0.0000\nTraining F1 Score = 0.8517 +/- 0.0042\nTest Accuracy = 0.4542 +/- 0.0000\nTest F1 Score = 0.8512 +/- 0.0176\nHamming Loss = 0.2753\n"
     ]
    }
   ],
   "source": [
    "best_classifier = grid_search(LabelPowerset(), search_space1)\n",
    "get_cross_val_results(LabelPowerset,best_classifier, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Ensemble Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4-1. Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model4 = RandomForestClassifier(random_state = 1024)\n",
    "hyperparameters = {'n_estimators' :[4,5,8,10,15,20], \"criterion\" :['gini', 'entropy'], 'max_leaf_nodes': [5,6,7,8,9,10,15], 'max_features': [8,9,10,11]}\n",
    "best_param = rfc_grid_search(model4, hyperparameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'bootstrap': True,\n",
       " 'ccp_alpha': 0.0,\n",
       " 'class_weight': None,\n",
       " 'criterion': 'entropy',\n",
       " 'max_depth': None,\n",
       " 'max_features': 8,\n",
       " 'max_leaf_nodes': 15,\n",
       " 'max_samples': None,\n",
       " 'min_impurity_decrease': 0.0,\n",
       " 'min_impurity_split': None,\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 2,\n",
       " 'min_weight_fraction_leaf': 0.0,\n",
       " 'n_estimators': 10,\n",
       " 'n_jobs': None,\n",
       " 'oob_score': False,\n",
       " 'random_state': 1024,\n",
       " 'verbose': 0,\n",
       " 'warm_start': False}"
      ]
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "source": [
    "best_param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training Accuracy = 0.4481 +/- 0.0000\nTraining F1 Score = 0.8546 +/- 0.0060\nTest Accuracy = 0.4257 +/- 0.0415\nTest F1 Score = 0.8495 +/- 0.0183\nHamming Loss = 0.2653\n"
     ]
    }
   ],
   "source": [
    "model4 = RandomForestClassifier(bootstrap= True, criterion= \"entropy\", max_features= 8, max_leaf_nodes= 15, n_estimators=10,random_state=1024)\n",
    "\n",
    "# train results\n",
    "results = cross_validate(model4, X_train, y_train, cv= kf, scoring =('accuracy', \"f1_weighted\"), return_train_score = True)\n",
    "train_accuracy = results['train_accuracy'].mean()\n",
    "train_f1 = results['train_f1_weighted']\n",
    "print(\"Training Accuracy = %.04f +/- %.04f\" % (train_accuracy.mean(), train_accuracy.std()*2))\n",
    "print(\"Training F1 Score = %.04f +/- %.04f\" % (train_f1.mean(), train_f1.std()*2))\n",
    "\n",
    "# test results\n",
    "y_pred = cross_val_predict(model4, X_test, y_test, cv=kf)\n",
    "test_accuracy = results['test_accuracy']\n",
    "test_f1 = results['test_f1_weighted']\n",
    "print(\"Test Accuracy = %.04f +/- %.04f\" % (test_accuracy.mean(), test_accuracy.std()*2))\n",
    "print(\"Test F1 Score = %.04f +/- %.04f\" % (test_f1.mean(), test_f1.std()*2))\n",
    "print(\"Hamming Loss = %.04f\" % (metrics.hamming_loss(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4-2. RAkELd: random label space partitioning with Label powerset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "RakelD(base_classifier=DecisionTreeClassifier(max_depth=5, max_leaf_nodes=5))\nTraining Accuracy = 0.4586 +/- 0.0000\nTraining F1 Score = 0.8521 +/- 0.0042\nTest Accuracy = 0.4471 +/- 0.0000\nTest F1 Score = 0.8490 +/- 0.0204\nHamming Loss = 0.2769\n"
     ]
    }
   ],
   "source": [
    "get_cross_val_results(RakelD, SVC(kernel='linear', random_state= 1024), X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Adaptive Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5-1. Multi-label K Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "best parameters : {'k': 7, 's': 0.5} best score:  -0.2929431362156432\n"
     ]
    }
   ],
   "source": [
    "parameters = {'k': range(1,9), \n",
    "              's': [0.5, 0.7, 1.0]}\n",
    "\n",
    "score = ham_loss\n",
    "classifier = GridSearchCV(MLkNN(), parameters, scoring=score)\n",
    "classifier.fit(X_train, y_train)\n",
    "print('best parameters :', classifier.best_params_, 'best score: ',\n",
    "      classifier.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training Accuracy = 0.4385\nTraining F1 Score = 0.8623\nAccuracy = 0.2869\nF1 Score = 0.8106\nHamming Loss = 0.3022\n"
     ]
    }
   ],
   "source": [
    "MlKnn = MLkNN(k= 7, s = .5)\n",
    "MlKnn.fit(X_train, y_train)\n",
    "train_pred = MlKnn.predict(X_train)\n",
    "pred = MlKnn.predict(X_test)\n",
    "\n",
    "print(\"Training Accuracy = %.04f\" % metrics.accuracy_score(y_train, train_pred))\n",
    "print(\"Training F1 Score = %.04f\" % metrics.f1_score(y_train, train_pred, average='weighted'))\n",
    "print(\"Accuracy = %.04f\" % metrics.accuracy_score(y_test, pred))\n",
    "print(\"F1 Score = %.04f\" % metrics.f1_score(y_test, pred, average='weighted'))\n",
    "print(\"Hamming Loss = %.04f\" % metrics.hamming_loss(y_test, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5-2. Binary Relevance K Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "best parameters : {'k': 7} best score:  -0.2886792357588147\n"
     ]
    }
   ],
   "source": [
    "parameters = {'k': range(3,9)}\n",
    "\n",
    "classifier = GridSearchCV(BRkNNaClassifier(), parameters, scoring=score)\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "print('best parameters :', classifier.best_params_,\n",
    "      'best score: ',classifier.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy = 0.2869\nF1 Score = 0.8106\nHamming Loss = 0.3022\n"
     ]
    }
   ],
   "source": [
    "BrKnn = BRkNNaClassifier(k= 7)\n",
    "BrKnn.fit(X_train, y_train)\n",
    "pred = BrKnn.predict(X_test)\n",
    "print(\"Accuracy = %.04f\" % metrics.accuracy_score(y_test, pred))\n",
    "print(\"F1 Score = %.04f\" % metrics.f1_score(y_test, pred, average='weighted'))\n",
    "print(\"Hamming Loss = %.04f\" % metrics.hamming_loss(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.3 64-bit (conda)",
   "metadata": {
    "interpreter": {
     "hash": "344443636c3027c5042750c9c609acdda283a9c43681b128a8c1053e7ad2aa7d"
    }
   }
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}