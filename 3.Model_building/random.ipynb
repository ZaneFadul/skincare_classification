{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.3 64-bit (conda)",
   "metadata": {
    "interpreter": {
     "hash": "344443636c3027c5042750c9c609acdda283a9c43681b128a8c1053e7ad2aa7d"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import csv \n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.over_sampling import RandomOverSampler \n",
    "from imblearn.under_sampling import RandomUnderSampler \n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import os \n",
    "\n",
    "os.chdir(\"/Users/susanchen/Documents/GitHub/skincare_classification/Plots\")\n",
    "from collections import Counter "
   ]
  },
  {
   "source": [
    "## Building Multi-label Classifiers \n",
    "### Base Classifiers to test: Binary Relevance (no correlation), Binary Relevance (with correlation), Multi-label Random Forest, Multi-label Decision Tree, Classifier Chain, Binary Releveance with Stacking Aggregation, Cross-Coupling Aggregation (to combat class-imbalances)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 670,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('/Users/susanchen/Documents/GitHub/skincare_classification/Data_sets/Master_cleaned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 834,
   "metadata": {},
   "outputs": [],
   "source": [
    "smallClasses = [\"['Oily', 'Sensitive']\", \"['Dry', 'Normal', 'Oily']\", \"['Dry', 'Oily']\", \"['Dry', 'Normal', 'Oily', 'Sensitive']\"]\n",
    "data = data[data.Skin_Type != \"['Oily', 'Sensitive']\"]\n",
    "data = data[data.Skin_Type != \"['Dry', 'Normal', 'Oily']\"]\n",
    "data = data[data.Skin_Type != \"['Dry', 'Oily']\"]\n",
    "data = data[data.Skin_Type != \"['Dry', 'Normal', 'Oily', 'Sensitive']\"]\n",
    "data = data[data.Skin_Type != \"['Combination', 'Dry', 'Oily', 'Sensitive']\"]\n",
    "data = data[data.Skin_Type != \"['Normal', 'Oily']\"]\n",
    "\n",
    "X = data[data.columns[12:23]].values\n",
    "y = data.Skin_Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 835,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Counter({\"['Combination', 'Dry', 'Normal', 'Oily', 'Sensitive']\": 918, \"['Combination', 'Dry', 'Normal', 'Oily']\": 239, \"['Combination', 'Normal', 'Oily']\": 113, \"['Combination', 'Oily']\": 91, \"['Normal']\": 83, \"['Dry', 'Normal']\": 72, \"['Dry']\": 71, \"['Combination', 'Dry', 'Normal']\": 66, \"['Combination', 'Dry', 'Normal', 'Sensitive']\": 61, \"['Combination']\": 59, \"['Sensitive']\": 46, \"['Combination', 'Normal']\": 30, \"['Dry', 'Normal', 'Sensitive']\": 29, \"['Oily']\": 26, \"['Combination', 'Normal', 'Oily', 'Sensitive']\": 23, \"['Combination', 'Dry']\": 22, \"['Dry', 'Sensitive']\": 19, \"['Combination', 'Dry', 'Oily']\": 13, \"['Normal', 'Sensitive']\": 12, \"['Combination', 'Oily', 'Sensitive']\": 10, \"['Combination', 'Dry', 'Sensitive']\": 7})\n"
     ]
    }
   ],
   "source": [
    "X = data[data.columns[12:23]].values\n",
    "y = data.Skin_Type\n",
    "#['Oily', 'Sensitive']\": 2, \"['Dry', 'Normal', 'Oily']\": 2, \"['Dry', 'Oily']\": 1, \"['Dry', 'Normal', 'Oily', 'Sensitive']\": 1\n",
    "#\"['Combination', 'Dry', 'Oily', 'Sensitive']\": 4, \"['Normal', 'Oily']\": 4\n",
    "#summarize class distribution \n",
    "counter = Counter(y)\n",
    "print(counter)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 836,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Dataset sizes:\n\tTrain (1407, 11)\n\tVal (301, 11)\n\tTest (302, 11)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MultiLabelBinarizer \n",
    "\n",
    "X = data[data.columns[12:23]].values\n",
    "y = data[\"Skin_Type\"].to_numpy()\n",
    "\n",
    "\n",
    "X_train, X_holdout, y_train, y_holdout = train_test_split(X, y, shuffle=True, test_size=0.3, random_state = 1024)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_holdout, y_holdout, shuffle=False, test_size=0.5, random_state = 1024)\n",
    "\n",
    "print(\"Dataset sizes:\\n\\tTrain %s\\n\\tVal %s\\n\\tTest %s\" % (X_train.shape, X_val.shape,X_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 837,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Before resampling:\nCounter({\"['Combination', 'Dry', 'Normal', 'Oily', 'Sensitive']\": 652, \"['Combination', 'Dry', 'Normal', 'Oily']\": 166, \"['Combination', 'Normal', 'Oily']\": 81, \"['Combination', 'Oily']\": 71, \"['Dry']\": 53, \"['Normal']\": 53, \"['Combination', 'Dry', 'Normal', 'Sensitive']\": 45, \"['Dry', 'Normal']\": 43, \"['Combination', 'Dry', 'Normal']\": 41, \"['Combination']\": 40, \"['Sensitive']\": 29, \"['Combination', 'Normal']\": 22, \"['Dry', 'Normal', 'Sensitive']\": 17, \"['Dry', 'Sensitive']\": 17, \"['Combination', 'Dry']\": 16, \"['Oily']\": 16, \"['Combination', 'Normal', 'Oily', 'Sensitive']\": 14, \"['Combination', 'Dry', 'Oily']\": 9, \"['Normal', 'Sensitive']\": 9, \"['Combination', 'Oily', 'Sensitive']\": 7, \"['Combination', 'Dry', 'Sensitive']\": 6})\n\nAfter resampling:\nCounter({\"['Combination', 'Dry', 'Normal', 'Oily', 'Sensitive']\": 652, \"['Combination', 'Dry', 'Normal', 'Oily']\": 166, \"['Combination', 'Dry', 'Normal', 'Sensitive']\": 100, \"['Combination', 'Dry', 'Normal']\": 100, \"['Combination']\": 100, \"['Dry', 'Normal']\": 100, \"['Combination', 'Normal', 'Oily']\": 100, \"['Dry']\": 100, \"['Combination', 'Oily']\": 100, \"['Normal']\": 100, \"['Combination', 'Dry']\": 50, \"['Combination', 'Dry', 'Oily']\": 50, \"['Sensitive']\": 50, \"['Dry', 'Normal', 'Sensitive']\": 50, \"['Combination', 'Dry', 'Sensitive']\": 50, \"['Oily']\": 50, \"['Combination', 'Oily', 'Sensitive']\": 50, \"['Combination', 'Normal']\": 50, \"['Dry', 'Sensitive']\": 50, \"['Normal', 'Sensitive']\": 50, \"['Combination', 'Normal', 'Oily', 'Sensitive']\": 50})\n"
     ]
    }
   ],
   "source": [
    "#SMOTE\n",
    "# transform the dataset\n",
    "#['Combination', 'Dry', 'Normal', 'Oily', 'Sensitive']\": 652, \"['Combination', 'Dry', 'Normal', 'Oily']\": 166\n",
    "num = 100\n",
    "num2 = 50\n",
    "# summarize the class distribution\n",
    "counter = Counter(y_train)\n",
    "print(\"Before resampling:\") \n",
    "print (counter)\n",
    "oversample = SMOTE(k_neighbors = 3, sampling_strategy = {\"['Combination', 'Normal', 'Oily']\": num, \"['Combination', 'Oily']\": num, \"['Dry']\": num, \"['Normal']\": num, \"['Combination', 'Dry', 'Normal', 'Sensitive']\": num, \"['Dry', 'Normal']\": num, \"['Combination', 'Dry', 'Normal']\": num, \"['Combination']\": num, \"['Sensitive']\": num2, \"['Combination', 'Normal']\": num2, \"['Dry', 'Normal', 'Sensitive']\": num2, \"['Dry', 'Sensitive']\": num2, \"['Combination', 'Dry']\": num2, \"['Oily']\": num2, \"['Combination', 'Normal', 'Oily', 'Sensitive']\": num2, \"['Combination', 'Dry', 'Oily']\": num2, \"['Normal', 'Sensitive']\": num2, \"['Combination', 'Oily', 'Sensitive']\": num2, \"['Combination', 'Dry', 'Sensitive']\": num2})\n",
    "X_train, y_train = oversample.fit_resample(X_train, y_train)\n",
    "\n",
    "# summarize the new class distribution\n",
    "#under = RandomUnderSampler(sampling_strategy= {\"['Combination', 'Dry', 'Normal', 'Oily', 'Sensitive']\": 600})\n",
    "#X_train, y_train = under.fit_resample(X_train, y_train)\n",
    "\n",
    "counter = Counter(y_train)\n",
    "print()\n",
    "print(\"After resampling:\") \n",
    "print(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 838,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Dataset sizes:\n\tTrain (2168, 11)\n\tVal (301, 11)\n\tTest (302, 11)\n"
     ]
    }
   ],
   "source": [
    "print(\"Dataset sizes:\\n\\tTrain %s\\n\\tVal %s\\n\\tTest %s\" % (X_train.shape, X_val.shape,X_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 839,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([\"['Combination', 'Dry', 'Normal', 'Oily']\",\n",
       "       \"['Combination', 'Dry', 'Normal', 'Oily', 'Sensitive']\",\n",
       "       \"['Combination', 'Dry', 'Normal', 'Sensitive']\", ...,\n",
       "       \"['Sensitive']\", \"['Sensitive']\", \"['Sensitive']\"], dtype=object)"
      ]
     },
     "metadata": {},
     "execution_count": 839
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 840,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(y_train)):\n",
    "    y_train[i] = [y_train[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 841,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlb = MultiLabelBinarizer(classes = ('Combination', 'Dry', 'Normal', 'Oily', 'Sensitive'))\n",
    "y_train = mlb.fit_transform(y_train)\n",
    "\n",
    "#a = mlb.fit_transform(set(data['Skin_Type'].str.split(', '))) \n",
    "#y_val = mlb.fit_transform(y_val)\n",
    "#y_test = mlb.fit_transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 842,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array(['Combination', 'Dry', 'Normal', 'Oily', 'Sensitive'], dtype=object)"
      ]
     },
     "metadata": {},
     "execution_count": 842
    }
   ],
   "source": [
    "mlb.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 845,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0]])"
      ]
     },
     "metadata": {},
     "execution_count": 845
    }
   ],
   "source": [
    "y_train[:10]"
   ]
  },
  {
   "source": [
    "## Binary Relevance with Gaussian "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy =  0.14950166112956811\nF1 Score =  0.7266277128547579\nHamming Loss 0.3784486494294381\n"
     ]
    }
   ],
   "source": [
    "from skmultilearn.problem_transform import BinaryRelevance\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "import sklearn.metrics as metrics\n",
    "# initialize binary relevance multi-label classifier with a gaussian naive bayes base classifier\n",
    "classifier = BinaryRelevance(\n",
    "    classifier = GaussianNB(),\n",
    "    require_dense=[True, True] \n",
    ")\n",
    "# train\n",
    "classifier.fit(X_train, y_train)\n",
    "# predict\n",
    "predictions = classifier.predict(X_val)\n",
    "# accuracy\n",
    "print(\"Accuracy = \", metrics.accuracy_score(y_val,predictions))\n",
    "print(\"F1 Score = \", metrics.f1_score(y_val,predictions, average = \"micro\"))\n",
    "print(\"Hamming Loss\", metrics.hamming_loss(y_val, predictions))\n"
   ]
  },
  {
   "source": [
    "## One vs the Rest Classifier "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy =  0.2956810631229236\nF1 Score =  0.8926022336048367\nHamming Loss 0.18474649718330205\n"
     ]
    }
   ],
   "source": [
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "classif = OneVsRestClassifier(SVC(kernel='linear', random_state= 1024))\n",
    "classif.fit(X_train, y_train)\n",
    "val_pred = classif.predict(X_val)\n",
    "# accuracy\n",
    "print(\"Accuracy = \", metrics.accuracy_score(y_val, val_pred))\n",
    "print(\"F1 Score = \", metrics.f1_score(y_val,val_pred, average = \"micro\"))\n",
    "print(\"Hamming Loss\", metrics.hamming_loss(y_val, val_pred))"
   ]
  },
  {
   "source": [
    "## Decision Tree Classifier"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=DecisionTreeClassifier(),\n",
       "             param_grid={'max_depth': [5, 6, 7, 8, 9],\n",
       "                         'max_leaf_nodes': [5, 10, 15]},\n",
       "             scoring='accuracy')"
      ]
     },
     "metadata": {},
     "execution_count": 122
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "dt =  DecisionTreeClassifier()\n",
    "param_grid = {\n",
    "    'max_depth' :[5,6,7,8,9],\n",
    "    'max_leaf_nodes': [5,10,15]\n",
    "}\n",
    "gs = GridSearchCV(dt, param_grid, scoring = \"accuracy\", cv= 5)\n",
    "\n",
    "gs.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.8405563032750112\n"
     ]
    }
   ],
   "source": [
    "tree = dt.fit(X_train, y_train)\n",
    "y_pred = tree.predict(X_test)\n",
    "print(metrics.f1_score(y_test, y_pred, average=\"micro\"))"
   ]
  },
  {
   "source": [
    "  ## Binary Relevance with Random Forest Classifier "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "training time taken:  14.0 seconds\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import time \n",
    "start=time.time()\n",
    "classifier = BinaryRelevance(\n",
    "    classifier = RandomForestClassifier(),\n",
    "    require_dense = [False, True]\n",
    ")\n",
    "\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "print('training time taken: ',round(time.time()-start,0),'seconds')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Binary Relevance accuracy: 0.252\nBinary Relevance F1-score: 0.881\nBinary Relevance Hamming Loss: 0.201\n"
     ]
    }
   ],
   "source": [
    "y_hat=classifier.predict(X_test)\n",
    "a=metrics.accuracy_score(y_test, y_hat)\n",
    "br_f1=metrics.f1_score(y_test, y_hat, average='micro')\n",
    "br_hamm=metrics.hamming_loss(y_test,y_hat)\n",
    "\n",
    "print('Binary Relevance accuracy:',round(a,3))\n",
    "print('Binary Relevance F1-score:',round(br_f1,3))\n",
    "print('Binary Relevance Hamming Loss:',round(br_hamm,3))"
   ]
  },
  {
   "source": [
    "## Label Powerset with Random Forest Classifier"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "training time taken:  1.0 seconds\n"
     ]
    }
   ],
   "source": [
    "from skmultilearn.problem_transform import LabelPowerset\n",
    "\n",
    "classifier = LabelPowerset(\n",
    "    classifier = RandomForestClassifier(),\n",
    "    require_dense = [False, True]\n",
    ")\n",
    "\n",
    "start=time.time()\n",
    "classifier.fit(X_train, y_train)\n",
    "print('training time taken: ',round(time.time()-start,0),'seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Binary Relevance accuracy: 0.334\nLabel Powerset F1-score: 0.87\nLabel Powerset Hamming Loss: 0.219\n"
     ]
    }
   ],
   "source": [
    "y_hat=classifier.predict(X_test)\n",
    "lp_a=metrics.accuracy_score(y_test, y_hat)\n",
    "lp_f1=metrics.f1_score(y_test, y_hat, average='micro')\n",
    "lp_hamm=metrics.hamming_loss(y_test,y_hat)\n",
    "print('Binary Relevance accuracy:',round(lp_a,3))\n",
    "print('Label Powerset F1-score:',round(lp_f1,3))\n",
    "print('Label Powerset Hamming Loss:',round(lp_hamm,3))"
   ]
  },
  {
   "source": [
    "## Multi-label K Nearest Neighbors"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "training time taken:  86.0 seconds\nbest parameters : {'k': 2, 's': 0.5} best score:  0.8640679016137314\n"
     ]
    }
   ],
   "source": [
    "from skmultilearn.adapt import MLkNN\n",
    "import time\n",
    "\n",
    "parameters = {'k': range(1,3), \n",
    "              's': [0.5, 0.7, 1.0]}\n",
    "\n",
    "score = 'f1_micro'\n",
    "\n",
    "start=time.time()\n",
    "\n",
    "classifier = GridSearchCV(MLkNN(), parameters, scoring=score)\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "print('training time taken: ',round(time.time()-start,0),'seconds')\n",
    "print('best parameters :', classifier.best_params_, 'best score: ',\n",
    "      classifier.best_score_)"
   ]
  },
  {
   "source": [
    "## "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Binary Relevance K-Nearest Neighbors"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "training time taken:  2.0 seconds\nbest parameters : {'k': 3} best score:  0.8347857185580414\n"
     ]
    }
   ],
   "source": [
    "from skmultilearn.adapt import BRkNNaClassifier\n",
    "\n",
    "parameters = {'k': range(3,5)}\n",
    "score = 'f1_samples'\n",
    "\n",
    "start=time.time()\n",
    "\n",
    "classifier = GridSearchCV(BRkNNaClassifier(), parameters, scoring=score)\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "print('training time taken: ',round(time.time()-start,0),'seconds')\n",
    "print('best parameters :', classifier.best_params_,\n",
    "      'best score: ',classifier.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.24834437086092714\n0.8625294579732913\n"
     ]
    }
   ],
   "source": [
    "BrKnn = BRkNNaClassifier(k= 3)\n",
    "BrKnn.fit(X_train, y_train)\n",
    "pred = BrKnn.predict(X_test)\n",
    "print(metrics.accuracy_score(y_test, pred))\n",
    "print(metrics.f1_score(y_test, pred, average='micro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.io as sio\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratio= 0.1\n",
    "\n",
    "def mLIFT(train_data,train_target,test_data,test_target,ratio):\n",
    "    num_train, dim= train_data.shape\n",
    "    num_test, num_class= test_target.shape\n",
    "    \n",
    "    P_Centers= []\n",
    "    N_Centers= []\n",
    "    \n",
    "    ##### KMeans, and save the centers\n",
    "    for i in range(num_class):\n",
    "        print (\"Performing clustering:%d/%d\" %(i+ 1, num_class))\n",
    "    \n",
    "        p_data= train_data[train_target[:,i]== 1]\n",
    "        n_data= train_data[train_target[:,i]== -1]\n",
    "    \n",
    "        k1= int(min( math.ceil(p_data.shape[0]* ratio), math.ceil(n_data.shape[0]* ratio) ))\n",
    "        #print(\"k1= k2= %d\" %k1)\n",
    "        k2= k1;\n",
    "    \n",
    "        if(k1== 0):\n",
    "            POS_C=[]\n",
    "            zero_kmeans= KMeans(n_clusters= min(50, num_train)).fit(train_data)\n",
    "            NEG_C= zero_kmeans.cluster_centers_\n",
    "        else:\n",
    "            # Positive\n",
    "            if(p_data.shape[0]== 1):\n",
    "                POS_C= p_data\n",
    "            else:\n",
    "                p_kmeans= KMeans(n_clusters= k1).fit(p_data)\n",
    "                POS_C= p_kmeans.cluster_centers_\n",
    "            # Negative\n",
    "            if(n_data.shape[0]== 1):\n",
    "                NEG_C= n_data\n",
    "            else:\n",
    "                n_kmeans= KMeans(n_clusters= k2).fit(n_data)\n",
    "                NEG_C= n_kmeans.cluster_centers_\n",
    "                \n",
    "        # Save the cluster centers\n",
    "        P_Centers.append(POS_C)\n",
    "        N_Centers.append(NEG_C)\n",
    "            \n",
    "    #print(\"The size of P_Canters is %d\\n\" %len(P_Centers))\n",
    "    \n",
    "    ##### Do the map and save the models\n",
    "    Models= []\n",
    "    for i in range(num_class):\n",
    "        print (\"Building classifiers: :%d/%d\" %(i+ 1, num_class))\n",
    "        centers= np.vstack((P_Centers[i+1], N_Centers[i+1]))\n",
    "        num_center= centers.shape[0]\n",
    "        # print(num_center)\n",
    "        data= []\n",
    "    \n",
    "        if(num_center>= 5000):\n",
    "            print(\"Too many cluster center!\")\n",
    "            break\n",
    "        else:\n",
    "            blocksize= 5000- num_center\n",
    "            num_block= int(math.ceil(num_train/ blocksize))\n",
    "            # print(num_block)\n",
    "            \n",
    "            mFirst= True\n",
    "            for j in range(num_block- 1):\n",
    "                print(j)\n",
    "                low= j* blocksize\n",
    "                high= (j+ 1)* blocksize\n",
    "                # Calculate the distance\n",
    "                for k in range(num_center):\n",
    "                    diff= train_data[low:high, :]- centers[k]\n",
    "                    Eu_diff= np.linalg.norm(diff, axis=1)\n",
    "                    if(mFirst== True):\n",
    "                        mFirst= False\n",
    "                        data_temp= Eu_diff\n",
    "                    else:\n",
    "                        data_temp= np.vstack((data_temp, Eu_diff))\n",
    "                    \n",
    "            \n",
    "            low= (num_block- 1)* blocksize\n",
    "            high= num_train\n",
    "            \n",
    "            # Calculate the distance\n",
    "            for j in range(num_center):\n",
    "                diff= train_data[low:high,:]- centers[j]\n",
    "                Eu_diff= np.linalg.norm(diff, axis=1)\n",
    "                if(mFirst== True):\n",
    "                    mFirst= False\n",
    "                    data_temp= Eu_diff\n",
    "                else:\n",
    "                    data_temp= np.vstack((data_temp, Eu_diff))\n",
    "            \n",
    "            data= data_temp.T\n",
    "        \n",
    "        training_instance_matrix= data\n",
    "        training_label_vector= train_target[:,i]\n",
    "    \n",
    "        model_this= SVC(C= 10, probability=True).fit(training_instance_matrix, training_label_vector)\n",
    "        #model_this= LogisticRegression(C= 0.03).fit(training_instance_matrix, training_label_vector)\n",
    "        #model_this= DecisionTreeClassifier().fit(training_instance_matrix, training_label_vector)\n",
    "        #model_this = AdaBoostClassifier(DecisionTreeClassifier(),\n",
    "                         #algorithm=\"SAMME\",\n",
    "                         #n_estimators=50, learning_rate=0.8).fit(training_instance_matrix, training_label_vector)\n",
    "        Models.append(model_this)\n",
    "    \n",
    "    ##### Predict\n",
    "    for i in range(num_class):\n",
    "        print (\"Predicting: :%d/%d\" %(i+ 1, num_class))\n",
    "        centers= np.vstack((P_Centers[i], N_Centers[i]))\n",
    "        num_center= centers.shape[0]\n",
    "        # print(num_center)\n",
    "        data= []\n",
    "    \n",
    "        if(num_center>= 5000):\n",
    "            print(\"Too many cluster center!\")\n",
    "            break\n",
    "        else:\n",
    "            blocksize= 5000- num_center\n",
    "            num_block= int(math.ceil(num_test/ blocksize))\n",
    "            # print(num_block)\n",
    "            \n",
    "            mFirst= True\n",
    "            for j in range(num_block- 1):\n",
    "                print(j)\n",
    "                low= j* blocksize\n",
    "                high= (j+ 1)* blocksize\n",
    "                # Calculate the distance\n",
    "                for k in range(num_center):\n",
    "                    diff= test_data[low:high, :]- centers[k]\n",
    "                    Eu_diff= np.linalg.norm(diff, axis=1)\n",
    "                    if(mFirst== True):\n",
    "                        mFirst= False\n",
    "                        data_temp= Eu_diff\n",
    "                    else:\n",
    "                        data_temp= np.vstack((data_temp, Eu_diff))\n",
    "                    \n",
    "            \n",
    "            low= (num_block- 1)* blocksize\n",
    "            high= num_train\n",
    "            \n",
    "            # Calculate the distance\n",
    "            for j in range(num_center):\n",
    "                diff= test_data[low:high,:]- centers[j]\n",
    "                Eu_diff= np.linalg.norm(diff, axis=1)\n",
    "                if(mFirst== True):\n",
    "                    mFirst= False\n",
    "                    data_temp= Eu_diff\n",
    "                else:\n",
    "                    data_temp= np.vstack((data_temp, Eu_diff))\n",
    "            \n",
    "            data= data_temp.T\n",
    "            # print(data.shape)\n",
    "    \n",
    "        testing_instance_matrix= data;\n",
    "        testing_label_vector= test_target[:, i]\n",
    "    \n",
    "        predicted_label= Models[i].predict(testing_instance_matrix)\n",
    "        \n",
    "        #print (predicted_label)\n",
    "\n",
    "        print(\"The accuracy is: %f\" %accuracy_score(testing_label_vector, predicted_label))\n",
    "        #print(roc_auc_score(testing_label_vector, predicted_label))\n",
    "    \n",
    "    return 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 2, got 1)",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-208-4a227fc93e8f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmLIFT\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mratio\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-206-20bf6defff46>\u001b[0m in \u001b[0;36mmLIFT\u001b[0;34m(train_data, train_target, test_data, test_target, ratio)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmLIFT\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_target\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_target\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mratio\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mnum_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mnum_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_class\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mtest_target\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mP_Centers\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: not enough values to unpack (expected 2, got 1)"
     ]
    }
   ],
   "source": [
    "mLIFT(X_train,y_train, X_test,y_test,ratio);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'P_Centers' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-162-d5d2c13b90a6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mP_Centers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'P_Centers' is not defined"
     ]
    }
   ],
   "source": [
    "print(P_Centers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "IndexError",
     "evalue": "boolean index did not match indexed array along dimension 1; dimension is 11 but corresponding boolean dimension is 23",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-173-c3e9b18e0bb6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mp_data\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m: boolean index did not match indexed array along dimension 1; dimension is 11 but corresponding boolean dimension is 23"
     ]
    }
   ],
   "source": [
    "p_data= X_train[y_train== 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(2168, 11)"
      ]
     },
     "metadata": {},
     "execution_count": 170
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(2168, 23)"
      ]
     },
     "metadata": {},
     "execution_count": 169
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}