{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Synthetic Minority Oversampling Technique (SMOTE)\n",
    "### Using SMOTE to oversample the minority classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generic library imports and data import\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv\n",
    "import ast\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data = pd.read_csv('../Data_sets/Master_cleaned.csv')\n",
    "\n",
    "#Functions\n",
    "\n",
    "def remove_unwanted_observations(data, unwanted_observations = [\"['Oily', 'Sensitive']\",\n",
    "                                                                \"['Dry', 'Normal', 'Oily']\",\n",
    "                                                                \"['Dry', 'Oily']\",\n",
    "                                                                \"['Dry', 'Normal', 'Oily', 'Sensitive']\",\n",
    "                                                                \"['Combination', 'Dry', 'Oily', 'Sensitive']\",\n",
    "                                                                \"['Normal', 'Oily']\"\n",
    "                                                                ]):\n",
    "    for observation in unwanted_observations:\n",
    "        data = data[data.Skin_Type != observation]\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specific Libary imports and functions\n",
    "from collections import Counter\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from skmultilearn.problem_transform import LabelPowerset, BinaryRelevance, ClassifierChain\n",
    "from sklearn.model_selection import KFold, GridSearchCV, cross_validate, cross_val_score, cross_val_predict\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "import sklearn.metrics as metrics\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle = True, random_state=1024)\n",
    "\n",
    "def grid_search (model, search_space):\n",
    "    pipe = Pipeline([(\"classifier\", model)])\n",
    "    gs = GridSearchCV(pipe, search_space, scoring = \"accuracy\", cv= kf)\n",
    "    gs.fit(X_train, y_train)\n",
    "    return gs.best_estimator_.get_params()[\"classifier\"]\n",
    "\n",
    "def rfc_grid_search(model, hyperparameters):\n",
    "    gs = GridSearchCV(model, hyperparameters, scoring = ham_loss, cv= kf)\n",
    "    gs.fit(X_train, y_train)\n",
    "    return gs.best_estimator_.get_params()\n",
    "\n",
    "def get_cross_val_results (clf, base_classifier, X, y, X_test,y_test):\n",
    "    try: \n",
    "        model = clf(classifier = best_classifier)\n",
    "    except TypeError:\n",
    "        model = clf(base_classifier = best_classifier)\n",
    "    results = cross_validate(model, X, y, cv= kf, scoring =('accuracy', \"f1_weighted\"), return_train_score = True)\n",
    "    # train results \n",
    "    train_accuracy = results['train_accuracy'].mean()\n",
    "    train_f1 = results['train_f1_weighted']\n",
    "    print(model)\n",
    "    print(\"Training Accuracy = %.04f +/- %.04f\" % (train_accuracy.mean(), train_accuracy.std()*2))\n",
    "    print(\"Training F1 Score = %.04f +/- %.04f\" % (train_f1.mean(), train_f1.std()*2))\n",
    "\n",
    "    # test results\n",
    "    y_pred = cross_val_predict(model, X_test, y_test, cv=kf)\n",
    "    test_accuracy = results['test_accuracy'].mean()\n",
    "    test_f1 = results['test_f1_weighted']\n",
    "    print(\"Test Accuracy = %.04f +/- %.04f\" % (test_accuracy.mean(), test_accuracy.std()*2))\n",
    "    print(\"Test F1 Score = %.04f +/- %.04f\" % (test_f1.mean(), test_f1.std()*2))\n",
    "    print(\"Hamming Loss = %.04f\" % metrics.hamming_loss(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Counter({\"['Combination', 'Dry', 'Normal', 'Oily', 'Sensitive']\": 918, \"['Combination', 'Dry', 'Normal', 'Oily']\": 239, \"['Combination', 'Normal', 'Oily']\": 113, \"['Combination', 'Oily']\": 91, \"['Normal']\": 83, \"['Dry', 'Normal']\": 72, \"['Dry']\": 71, \"['Combination', 'Dry', 'Normal']\": 66, \"['Combination', 'Dry', 'Normal', 'Sensitive']\": 61, \"['Combination']\": 59, \"['Sensitive']\": 46, \"['Combination', 'Normal']\": 30, \"['Dry', 'Normal', 'Sensitive']\": 29, \"['Oily']\": 26, \"['Combination', 'Normal', 'Oily', 'Sensitive']\": 23, \"['Combination', 'Dry']\": 22, \"['Dry', 'Sensitive']\": 19, \"['Combination', 'Dry', 'Oily']\": 13, \"['Normal', 'Sensitive']\": 12, \"['Combination', 'Oily', 'Sensitive']\": 10, \"['Combination', 'Dry', 'Sensitive']\": 7})\n"
     ]
    }
   ],
   "source": [
    "data = remove_unwanted_observations(data)\n",
    "X = data[data.columns[17:28]].values\n",
    "y = data.Skin_Type\n",
    "counter = Counter(y)\n",
    "print(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                        Product               Brand  \\\n",
       "0                     #InstantDetox Facial Mask            Biobelle   \n",
       "1                           #Peachy Facial Mask            Biobelle   \n",
       "2                       #Rise&Shine Facial Mask            Biobelle   \n",
       "3                       #RoséAllDay Facial Mask            Biobelle   \n",
       "4                       #VitaminSea Facial Mask            Biobelle   \n",
       "...                                         ...                 ...   \n",
       "2019  Youthful Vitamin C Fresh Radiance Essence                 No7   \n",
       "2020                      Yuza Sorbet Day Cream            Erborian   \n",
       "2021                Yuza Sorbet Night Treatment            Erborian   \n",
       "2022               Yuzu Overnight Moisture Mask  Earth Therapeutics   \n",
       "2023                             pHenomenal Gel                Pixi   \n",
       "\n",
       "                                            Ingredients  Price  \\\n",
       "0     Water, Butylene Glycol, Glycerin, Trehalose, H...   3.99   \n",
       "1     Water, Methylpropanediol, Butylene Glycol, Gly...   3.99   \n",
       "2     Water, Glycerin, Butylene Glycol, Triethylhexa...   3.99   \n",
       "3     Water, Methylpropanediol, Glycerin, Propanedio...   3.99   \n",
       "4     Water, Butylene Glycol, Glycerin, Hydroxyaceto...   3.99   \n",
       "...                                                 ...    ...   \n",
       "2019  Aqua (Water), Butylene Glycol, Glycerin, Gluco...  24.99   \n",
       "2020  Aqua/Water, Cyclomethicone, Glycerin, Nylon-12...  48.00   \n",
       "2021  Aqua/Water, Cyclomethicone, Glycerin, Cetearyl...  55.00   \n",
       "2022  Water (Aqua), Propanediol, Glycerin, Hydrogena...   7.00   \n",
       "2023  Aqua/Water/Eau, Glycerin, Glycereth-26, Betain...  24.00   \n",
       "\n",
       "                                              Skin_Type  Combination  Dry  \\\n",
       "0                                              ['Oily']            0    0   \n",
       "1                                               ['Dry']            0    1   \n",
       "2                                       ['Combination']            1    0   \n",
       "3                                       ['Combination']            1    0   \n",
       "4                                               ['Dry']            0    1   \n",
       "...                                                 ...          ...  ...   \n",
       "2019           ['Combination', 'Dry', 'Normal', 'Oily']            1    1   \n",
       "2020  ['Combination', 'Dry', 'Normal', 'Oily', 'Sens...            1    1   \n",
       "2021  ['Combination', 'Dry', 'Normal', 'Oily', 'Sens...            1    1   \n",
       "2022      ['Combination', 'Dry', 'Normal', 'Sensitive']            1    1   \n",
       "2023                                           ['Oily']            0    0   \n",
       "\n",
       "      Normal  Oily  Sensitive  ... num_of_Emollients num_of_Hydration  \\\n",
       "0          0     1          0  ...                 0                0   \n",
       "1          0     0          0  ...                 0                0   \n",
       "2          0     0          0  ...                 0                0   \n",
       "3          0     0          0  ...                 0                0   \n",
       "4          0     0          0  ...                 0                0   \n",
       "...      ...   ...        ...  ...               ...              ...   \n",
       "2019       1     1          0  ...                 0                0   \n",
       "2020       1     1          1  ...                 1                0   \n",
       "2021       1     1          1  ...                 2                0   \n",
       "2022       1     0          1  ...                 2                0   \n",
       "2023       0     1          0  ...                 0                0   \n",
       "\n",
       "     num_of_Skin-Restoring num_of_Plant Extracts  num_of_Preservatives  \\\n",
       "0                        0                     0                     0   \n",
       "1                        0                     0                     0   \n",
       "2                        0                     0                     0   \n",
       "3                        0                     1                     2   \n",
       "4                        0                     1                     0   \n",
       "...                    ...                   ...                   ...   \n",
       "2019                     0                     2                     3   \n",
       "2020                     0                     1                     1   \n",
       "2021                     0                     0                     0   \n",
       "2022                     0                     1                     0   \n",
       "2023                     0                     0                     0   \n",
       "\n",
       "     num_of_Skin-Softening num_of_Sensitizing  num_of_Skin-Replenishing  \\\n",
       "0                        0                  0                         1   \n",
       "1                        0                  0                         1   \n",
       "2                        0                  0                         1   \n",
       "3                        0                  0                         2   \n",
       "4                        0                  0                         1   \n",
       "...                    ...                ...                       ...   \n",
       "2019                     0                  0                         2   \n",
       "2020                     0                  0                         1   \n",
       "2021                     0                  0                         1   \n",
       "2022                     0                  0                         1   \n",
       "2023                     0                  0                         1   \n",
       "\n",
       "                                                  top_3  \\\n",
       "0          ['Butylene Glycol', 'Glycerin', 'Trehalose']   \n",
       "1     ['Methylpropanediol', 'Butylene Glycol', 'Glyc...   \n",
       "2     ['Glycerin', 'Butylene Glycol', 'Triethylhexan...   \n",
       "3      ['Methylpropanediol', 'Glycerin', 'Propanediol']   \n",
       "4     ['Butylene Glycol', 'Glycerin', 'Hydroxyacetop...   \n",
       "...                                                 ...   \n",
       "2019  ['Butylene Glycol', 'Glycerin', 'Gluconolactone']   \n",
       "2020         ['Cyclomethicone', 'Glycerin', 'Nylon-12']   \n",
       "2021  ['Cyclomethicone', 'Glycerin', 'Cetearyl Alcoh...   \n",
       "2022  ['Propanediol', 'Glycerin', 'Hydrogenated Poly...   \n",
       "2023            ['Glycerin', 'Glycereth-26', 'Betaine']   \n",
       "\n",
       "                                     top3_category_list  \n",
       "0     ['Texture Enhancer', 'Skin-Replenishing, Skin-...  \n",
       "1     [None, 'Texture Enhancer', 'Skin-Replenishing,...  \n",
       "2     ['Skin-Replenishing, Skin-Restoring', 'Texture...  \n",
       "3     [None, 'Skin-Replenishing, Skin-Restoring', None]  \n",
       "4     ['Texture Enhancer', 'Skin-Replenishing, Skin-...  \n",
       "...                                                 ...  \n",
       "2019  ['Texture Enhancer', 'Skin-Replenishing, Skin-...  \n",
       "2020  ['Emollients', 'Skin-Replenishing, Skin-Restor...  \n",
       "2021  ['Emollients', 'Skin-Replenishing, Skin-Restor...  \n",
       "2022  [None, 'Skin-Replenishing, Skin-Restoring', None]  \n",
       "2023  ['Skin-Replenishing, Skin-Restoring', None, None]  \n",
       "\n",
       "[2010 rows x 30 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Product</th>\n      <th>Brand</th>\n      <th>Ingredients</th>\n      <th>Price</th>\n      <th>Skin_Type</th>\n      <th>Combination</th>\n      <th>Dry</th>\n      <th>Normal</th>\n      <th>Oily</th>\n      <th>Sensitive</th>\n      <th>...</th>\n      <th>num_of_Emollients</th>\n      <th>num_of_Hydration</th>\n      <th>num_of_Skin-Restoring</th>\n      <th>num_of_Plant Extracts</th>\n      <th>num_of_Preservatives</th>\n      <th>num_of_Skin-Softening</th>\n      <th>num_of_Sensitizing</th>\n      <th>num_of_Skin-Replenishing</th>\n      <th>top_3</th>\n      <th>top3_category_list</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>#InstantDetox Facial Mask</td>\n      <td>Biobelle</td>\n      <td>Water, Butylene Glycol, Glycerin, Trehalose, H...</td>\n      <td>3.99</td>\n      <td>['Oily']</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>['Butylene Glycol', 'Glycerin', 'Trehalose']</td>\n      <td>['Texture Enhancer', 'Skin-Replenishing, Skin-...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>#Peachy Facial Mask</td>\n      <td>Biobelle</td>\n      <td>Water, Methylpropanediol, Butylene Glycol, Gly...</td>\n      <td>3.99</td>\n      <td>['Dry']</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>['Methylpropanediol', 'Butylene Glycol', 'Glyc...</td>\n      <td>[None, 'Texture Enhancer', 'Skin-Replenishing,...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>#Rise&amp;Shine Facial Mask</td>\n      <td>Biobelle</td>\n      <td>Water, Glycerin, Butylene Glycol, Triethylhexa...</td>\n      <td>3.99</td>\n      <td>['Combination']</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>['Glycerin', 'Butylene Glycol', 'Triethylhexan...</td>\n      <td>['Skin-Replenishing, Skin-Restoring', 'Texture...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>#RoséAllDay Facial Mask</td>\n      <td>Biobelle</td>\n      <td>Water, Methylpropanediol, Glycerin, Propanedio...</td>\n      <td>3.99</td>\n      <td>['Combination']</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>['Methylpropanediol', 'Glycerin', 'Propanediol']</td>\n      <td>[None, 'Skin-Replenishing, Skin-Restoring', None]</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>#VitaminSea Facial Mask</td>\n      <td>Biobelle</td>\n      <td>Water, Butylene Glycol, Glycerin, Hydroxyaceto...</td>\n      <td>3.99</td>\n      <td>['Dry']</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>['Butylene Glycol', 'Glycerin', 'Hydroxyacetop...</td>\n      <td>['Texture Enhancer', 'Skin-Replenishing, Skin-...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2019</th>\n      <td>Youthful Vitamin C Fresh Radiance Essence</td>\n      <td>No7</td>\n      <td>Aqua (Water), Butylene Glycol, Glycerin, Gluco...</td>\n      <td>24.99</td>\n      <td>['Combination', 'Dry', 'Normal', 'Oily']</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>3</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>['Butylene Glycol', 'Glycerin', 'Gluconolactone']</td>\n      <td>['Texture Enhancer', 'Skin-Replenishing, Skin-...</td>\n    </tr>\n    <tr>\n      <th>2020</th>\n      <td>Yuza Sorbet Day Cream</td>\n      <td>Erborian</td>\n      <td>Aqua/Water, Cyclomethicone, Glycerin, Nylon-12...</td>\n      <td>48.00</td>\n      <td>['Combination', 'Dry', 'Normal', 'Oily', 'Sens...</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>['Cyclomethicone', 'Glycerin', 'Nylon-12']</td>\n      <td>['Emollients', 'Skin-Replenishing, Skin-Restor...</td>\n    </tr>\n    <tr>\n      <th>2021</th>\n      <td>Yuza Sorbet Night Treatment</td>\n      <td>Erborian</td>\n      <td>Aqua/Water, Cyclomethicone, Glycerin, Cetearyl...</td>\n      <td>55.00</td>\n      <td>['Combination', 'Dry', 'Normal', 'Oily', 'Sens...</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>...</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>['Cyclomethicone', 'Glycerin', 'Cetearyl Alcoh...</td>\n      <td>['Emollients', 'Skin-Replenishing, Skin-Restor...</td>\n    </tr>\n    <tr>\n      <th>2022</th>\n      <td>Yuzu Overnight Moisture Mask</td>\n      <td>Earth Therapeutics</td>\n      <td>Water (Aqua), Propanediol, Glycerin, Hydrogena...</td>\n      <td>7.00</td>\n      <td>['Combination', 'Dry', 'Normal', 'Sensitive']</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>...</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>['Propanediol', 'Glycerin', 'Hydrogenated Poly...</td>\n      <td>[None, 'Skin-Replenishing, Skin-Restoring', None]</td>\n    </tr>\n    <tr>\n      <th>2023</th>\n      <td>pHenomenal Gel</td>\n      <td>Pixi</td>\n      <td>Aqua/Water/Eau, Glycerin, Glycereth-26, Betain...</td>\n      <td>24.00</td>\n      <td>['Oily']</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>['Glycerin', 'Glycereth-26', 'Betaine']</td>\n      <td>['Skin-Replenishing, Skin-Restoring', None, None]</td>\n    </tr>\n  </tbody>\n</table>\n<p>2010 rows × 30 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, shuffle=True, test_size=0.3, random_state = 1024, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Before resampling:\nCounter({\"['Combination', 'Dry', 'Normal', 'Oily', 'Sensitive']\": 643, \"['Combination', 'Dry', 'Normal', 'Oily']\": 167, \"['Combination', 'Normal', 'Oily']\": 79, \"['Combination', 'Oily']\": 64, \"['Normal']\": 58, \"['Dry', 'Normal']\": 50, \"['Dry']\": 50, \"['Combination', 'Dry', 'Normal']\": 46, \"['Combination', 'Dry', 'Normal', 'Sensitive']\": 43, \"['Combination']\": 41, \"['Sensitive']\": 32, \"['Combination', 'Normal']\": 21, \"['Dry', 'Normal', 'Sensitive']\": 20, \"['Oily']\": 18, \"['Combination', 'Dry']\": 16, \"['Combination', 'Normal', 'Oily', 'Sensitive']\": 16, \"['Dry', 'Sensitive']\": 13, \"['Combination', 'Dry', 'Oily']\": 9, \"['Normal', 'Sensitive']\": 9, \"['Combination', 'Oily', 'Sensitive']\": 7, \"['Combination', 'Dry', 'Sensitive']\": 5})\n\nAfter resampling:\nCounter({\"['Combination', 'Dry', 'Normal', 'Oily', 'Sensitive']\": 643, \"['Combination', 'Dry', 'Normal', 'Oily']\": 167, \"['Normal']\": 100, \"['Combination', 'Dry', 'Normal', 'Sensitive']\": 100, \"['Combination']\": 100, \"['Combination', 'Oily']\": 100, \"['Dry', 'Normal']\": 100, \"['Combination', 'Normal', 'Oily']\": 100, \"['Dry']\": 100, \"['Combination', 'Dry', 'Normal']\": 100, \"['Combination', 'Normal']\": 50, \"['Combination', 'Dry', 'Oily']\": 50, \"['Dry', 'Sensitive']\": 50, \"['Sensitive']\": 50, \"['Normal', 'Sensitive']\": 50, \"['Oily']\": 50, \"['Combination', 'Oily', 'Sensitive']\": 50, \"['Dry', 'Normal', 'Sensitive']\": 50, \"['Combination', 'Dry']\": 50, \"['Combination', 'Normal', 'Oily', 'Sensitive']\": 50, \"['Combination', 'Dry', 'Sensitive']\": 50})\n\n"
     ]
    }
   ],
   "source": [
    "#SMOTE\n",
    "num = 100\n",
    "num2 = 50\n",
    "\n",
    "# summarize the class distribution\n",
    "counter = Counter(y_train)\n",
    "print(f\"Before resampling:\\n{counter}\\n\") \n",
    "\n",
    "oversample = SMOTE(k_neighbors = 3, sampling_strategy = {\"['Combination', 'Normal', 'Oily']\": num, \n",
    "                                                         \"['Combination', 'Oily']\": num,\n",
    "                                                         \"['Dry']\": num,\n",
    "                                                         \"['Normal']\": num,\n",
    "                                                         \"['Combination', 'Dry', 'Normal', 'Sensitive']\": num,\n",
    "                                                         \"['Dry', 'Normal']\": num,\n",
    "                                                         \"['Combination', 'Dry', 'Normal']\": num,\n",
    "                                                         \"['Combination']\": num,\n",
    "                                                         \"['Sensitive']\": num2,\n",
    "                                                         \"['Combination', 'Normal']\": num2,\n",
    "                                                         \"['Dry', 'Normal', 'Sensitive']\": num2,\n",
    "                                                         \"['Dry', 'Sensitive']\": num2,\n",
    "                                                         \"['Combination', 'Dry']\": num2,\n",
    "                                                         \"['Oily']\": num2,\n",
    "                                                         \"['Combination', 'Normal', 'Oily', 'Sensitive']\": num2,\n",
    "                                                         \"['Combination', 'Dry', 'Oily']\": num2,\n",
    "                                                         \"['Normal', 'Sensitive']\": num2,\n",
    "                                                         \"['Combination', 'Oily', 'Sensitive']\": num2,\n",
    "                                                         \"['Combination', 'Dry', 'Sensitive']\": num2\n",
    "                                                        })\n",
    "X_train, y_train = oversample.fit_resample(X_train, y_train)\n",
    "\n",
    "# summarize the new class distribution\n",
    "counter = Counter(y_train)\n",
    "print(f\"After resampling:\\n{counter}\\n\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array(['Combination', 'Dry', 'Normal', 'Oily', 'Sensitive'], dtype=object)"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "y_train = y_train.apply(ast.literal_eval)\n",
    "y_test = y_test.apply(ast.literal_eval)\n",
    "\n",
    "mlb=MultiLabelBinarizer()\n",
    "y_train = mlb.fit_transform(y_train)\n",
    "y_test = mlb.transform(y_test)\n",
    "mlb.classes_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results after running SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_space1 = [{'classifier':[DecisionTreeClassifier()], 'classifier__max_depth' :[5,6,7,8,9],\n",
    "    'classifier__max_leaf_nodes': [5,6,7,8,9,10,15]},{'classifier': [RandomForestClassifier()], 'classifier__n_estimators': [5,8,10,12,14,15],'classifier__max_features': [[8,9,10,11], \"auto\", 'sqrt', 'log2']}, {'classifier': [SVC()], 'classifier__kernel':['rbf', 'linear']},{'classifier': [MultinomialNB()], 'classifier__alpha': [.7, 1.0]}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=5, shuffle = True, random_state=1024)\n",
    "ham_loss = metrics.make_scorer(metrics.hamming_loss, greater_is_better= False)\n",
    "mlb2 = MultiLabelBinarizer()\n",
    "y = mlb2.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "BinaryRelevance(classifier=RandomForestClassifier(max_features='log2',\n",
      "                                                  n_estimators=10),\n",
      "                require_dense=[True, True])\n",
      "Training Accuracy = 0.8516 +/- 0.0000\n",
      "Training F1 Score = 0.9643 +/- 0.0017\n",
      "Test Accuracy = 0.3444 +/- 0.0000\n",
      "Test F1 Score = 0.7913 +/- 0.0083\n",
      "Hamming Loss = 0.3154\n",
      "ClassifierChain(classifier=RandomForestClassifier(n_estimators=15),\n",
      "                require_dense=[True, True])\n",
      "Training Accuracy = 0.9045 +/- 0.0000\n",
      "Training F1 Score = 0.9642 +/- 0.0038\n",
      "Test Accuracy = 0.4486 +/- 0.0000\n",
      "Test F1 Score = 0.8053 +/- 0.0183\n",
      "Hamming Loss = 0.2889\n",
      "LabelPowerset(classifier=RandomForestClassifier(n_estimators=15),\n",
      "              require_dense=[True, True])\n",
      "Training Accuracy = 0.9190 +/- 0.0000\n",
      "Training F1 Score = 0.9689 +/- 0.0018\n",
      "Test Accuracy = 0.4556 +/- 0.0000\n",
      "Test F1 Score = 0.8042 +/- 0.0057\n",
      "Hamming Loss = 0.2975\n"
     ]
    }
   ],
   "source": [
    "model4 = RandomForestClassifier(random_state = 1024)\n",
    "hyperparameters = {'n_estimators' :[4,5,8,10,15,20], \"criterion\" :['gini', 'entropy'], 'max_leaf_nodes': [5,6,7,8,9,10,15], 'max_features': [8,9,10,11]}\n",
    "best_param = rfc_grid_search(model4, hyperparameters)\n",
    "\n",
    "clf = [BinaryRelevance, ClassifierChain, LabelPowerset]\n",
    "for classifier in clf:\n",
    "    best_classifier = grid_search(classifier(), search_space1)\n",
    "    get_cross_val_results(classifier,best_classifier, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc_SMOTE = RandomForestClassifier(random_state = 1024)\n",
    "best_param = rfc_grid_search(rfc_SMOTE, hyperparameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'bootstrap': True,\n",
       " 'ccp_alpha': 0.0,\n",
       " 'class_weight': None,\n",
       " 'criterion': 'gini',\n",
       " 'max_depth': None,\n",
       " 'max_features': 9,\n",
       " 'max_leaf_nodes': 15,\n",
       " 'max_samples': None,\n",
       " 'min_impurity_decrease': 0.0,\n",
       " 'min_impurity_split': None,\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 2,\n",
       " 'min_weight_fraction_leaf': 0.0,\n",
       " 'n_estimators': 15,\n",
       " 'n_jobs': None,\n",
       " 'oob_score': False,\n",
       " 'random_state': 1024,\n",
       " 'verbose': 0,\n",
       " 'warm_start': False}"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "best_param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training Accuracy = 0.2449 +/- 0.0000\nTraining F1 Score = 0.7863 +/- 0.0075\nTest Accuracy = 0.2306 +/- 0.0332\nTest F1 Score = 0.7744 +/- 0.0109\nHamming Loss = 0.2743\n"
     ]
    }
   ],
   "source": [
    "rfc_SMOTE = RandomForestClassifier(bootstrap= True, criterion= \"entropy\", max_features= 11, max_leaf_nodes= 15, n_estimators=10,random_state=1024)\n",
    "\n",
    "# train results\n",
    "results = cross_validate(rfc_SMOTE, X_train, y_train, cv= kf, scoring =('accuracy', \"f1_weighted\"), return_train_score = True)\n",
    "train_accuracy = results['train_accuracy'].mean()\n",
    "train_f1 = results['train_f1_weighted']\n",
    "print(\"Training Accuracy = %.04f +/- %.04f\" % (train_accuracy.mean(), train_accuracy.std()*2))\n",
    "print(\"Training F1 Score = %.04f +/- %.04f\" % (train_f1.mean(), train_f1.std()*2))\n",
    "\n",
    "# test results\n",
    "y_pred = cross_val_predict(rfc_SMOTE, X_test, y_test, cv=kf)\n",
    "test_accuracy = results['test_accuracy']\n",
    "test_f1 = results['test_f1_weighted']\n",
    "print(\"Test Accuracy = %.04f +/- %.04f\" % (test_accuracy.mean(), test_accuracy.std()*2))\n",
    "print(\"Test F1 Score = %.04f +/- %.04f\" % (test_f1.mean(), test_f1.std()*2))\n",
    "print(\"Hamming Loss = %.04f\" % (metrics.hamming_loss(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}